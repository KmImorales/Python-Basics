{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is Jeopardy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is slightly different than others you have encountered thus far. Instead of a step-by-step tutorial, this project contains a series of open-ended requirements which describe the project you'll be building. There are many possible ways to correctly fulfill all of these requirements, and you should expect to use the internet, Codecademy, and/or other resources when you encounter a problem that you cannot easily solve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will work to write several functions that investigate a dataset of _Jeopardy!_ questions and answers. Filter the dataset for topics that you're interested in, compute the average difficulty of those questions, and train to become the next Jeopardy champion!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to complete this project, you should have completed the Pandas lessons in the <a href=\"https://www.codecademy.com/learn/paths/analyze-data-with-python\">Analyze Data with Python Skill Path</a>. You can also find those lessons in the <a href=\"https://www.codecademy.com/learn/data-processing-pandas\">Data Analysis with Pandas course</a> or the <a href=\"https://www.codecademy.com/learn/paths/data-science/\">Data Scientist Career Path</a>.\n",
    "\n",
    "Finally, the <a href=\"https://www.codecademy.com/learn/practical-data-cleaning\">Practical Data Cleaning</a> course may also be helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We've provided a csv file containing data about the game show _Jeopardy!_ in a file named `jeopardy.csv`. Load the data into a DataFrame and investigate its contents. Try to print out specific columns.\n",
    "\n",
    "   Note that in order to make this project as \"real-world\" as possible, we haven't modified the data at all - we're giving it to you exactly how we found it. As a result, this data isn't as \"clean\" as the datasets you normally find on Codecademy. More specifically, there's something odd about the column names. After you figure out the problem with the column names, you may want to rename them to make your life easier for the rest of the project.\n",
    "   \n",
    "   In order to display the full contents of a column, we've added this line of code for you:\n",
    "   \n",
    "   ```py\n",
    "   pd.set_option('display.max_colwidth', None)\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "questions = pd.read_csv('jeopardy.csv')\n",
    "questions.columns = questions.columns.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Write a function that filters the dataset for questions that contains all of the words in a list of words. For example, when the list `[\"King\", \"England\"]` was passed to our function, the function returned a DataFrame of 49 rows. Every row had the strings `\"King\"` and `\"England\"` somewhere in its `\" Question\"`.\n",
    "\n",
    "   Test your function by printing out the column containing the question of each row of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4953                   Both England's King George V & FDR put their stamp of approval on this \"King of Hobbies\"\n",
      "6337     In retaliation for Viking raids, this \"Unready\" king of England attacks Norse areas of the Isle of Man\n",
      "9191                   This king of England beat the odds to trounce the French in the 1415 Battle of Agincourt\n",
      "11710              This Scotsman, the first Stuart king of England, was called \"The Wisest Fool in Christendom\"\n",
      "13454                                      It's the number that followed the last king of England named William\n",
      "Name: Question, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def filter_questions_by_words(df, words):\n",
    "    \"\"\"\n",
    "    Filters the dataset for rows where the 'Question' column contains all the words in the given list.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame containing the dataset.\n",
    "        words (list): A list of words to filter the questions by.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A filtered DataFrame containing rows where all the words appear in the 'Question' column.\n",
    "    \"\"\"\n",
    "    # Ensure the column name is consistent\n",
    "    if 'Question' not in df.columns:\n",
    "        raise KeyError(\"The dataset does not contain a 'Question' column.\")\n",
    "    \n",
    "    # Apply the filter\n",
    "    for word in words:\n",
    "        df = df[df['Question'].str.contains(word, case=False, na=False)]\n",
    "    return df\n",
    "\n",
    "words_to_filter = [\"King\", \"England\"]\n",
    "filtered_questions = filter_questions_by_words(questions, words_to_filter)\n",
    "\n",
    "# Print the filtered questions\n",
    "print(filtered_questions[\"Question\"].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Test your original function with a few different sets of words to try to find some ways your function breaks. Edit your function so it is more robust.\n",
    "\n",
    "   For example, think about capitalization. We probably want to find questions that contain the word `\"King\"` or `\"king\"`.\n",
    "   \n",
    "   You may also want to check to make sure you don't find rows that contain substrings of your given words. For example, our function found a question that didn't contain the word `\"king\"`, however it did contain the word `\"viking\"` &mdash; it found the `\"king\"` inside `\"viking\"`. Note that this also comes with some drawbacks &mdash; you would no longer find questions that contained words like `\"England's\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6337     In retaliation for Viking raids, this \"Unready\" king of England attacks Norse areas of the Isle of Man\n",
      "9191                   This king of England beat the odds to trounce the French in the 1415 Battle of Agincourt\n",
      "11710              This Scotsman, the first Stuart king of England, was called \"The Wisest Fool in Christendom\"\n",
      "13454                                      It's the number that followed the last king of England named William\n",
      "14912         This country's King Louis IV was nicknamed \"Louis From Overseas\" because he was raised in England\n",
      "Name: Question, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def filter_questions_by_words(df, words):\n",
    "    \"\"\"\n",
    "    Filters the dataset for rows where the 'Question' column contains all the words in the given list.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame containing the dataset.\n",
    "        words (list): A list of words to filter the questions by.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A filtered DataFrame containing rows where all the words appear in the 'Question' column.\n",
    "    \"\"\"\n",
    "    # Tokenize and clean each question to avoid substring matches\n",
    "    def contains_all_words(question, words):\n",
    "        # Split question into words, removing punctuation and lowercasing\n",
    "        tokens = set(word.strip(\".,'\\\"!?\").lower() for word in question.split())\n",
    "        # Check if all words are present in the tokens\n",
    "        return all(word.lower() in tokens for word in words)\n",
    "\n",
    "    # Apply the filtering logic\n",
    "    return df[df['Question'].apply(lambda q: contains_all_words(q, words))]\n",
    "\n",
    "words_to_filter = [\"king\", \"EngLand\"]\n",
    "filtered_questions = filter_questions_by_words(questions, words_to_filter)\n",
    "\n",
    "# Print the filtered questions\n",
    "print(filtered_questions[\"Question\"].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. We may want to eventually compute aggregate statistics, like `.mean()` on the `\" Value\"` column. But right now, the values in that column are strings. Convert the`\" Value\"` column to floats. If you'd like to, you can create a new column with float values.\n",
    "\n",
    "   While most of the values in the `\" Value\"` column represent a dollar amount as a string, note that some do not &mdash; these values will need to be handled differently!\n",
    "\n",
    "   Now that you can filter the dataset of question, use your new column that contains the float values of each question to find the \"difficulty\" of certain topics. For example, what is the average value of questions that contain the word `\"King\"`?\n",
    "   \n",
    "   Make sure to use the dataset that contains the float values as the dataset you use in your filtering function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Value\n",
      "0  200.0\n",
      "1  200.0\n",
      "2  200.0\n",
      "3  200.0\n",
      "4  200.0\n"
     ]
    }
   ],
   "source": [
    "def convert_to_float(value):\n",
    "    if isinstance(value, str):  # Check if the value is a string\n",
    "        try:\n",
    "            # Remove dollar signs and commas, and convert to float\n",
    "            return float(value.replace('$', '').replace(',', ''))\n",
    "        except ValueError:\n",
    "            return None\n",
    "    return value  # Return the value as-is if it's already a float or None\n",
    "\n",
    "# Apply the function to \"Value\" column\n",
    "questions[\"Value\"] = questions[\"Value\"].apply(convert_to_float)\n",
    "\n",
    "print(questions[[\"Value\"]].head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Write a function that returns the count of unique answers to all of the questions in a dataset. For example, after filtering the entire dataset to only questions containing the word `\"King\"`, we could then find all of the unique answers to those questions. The answer \"Henry VIII\" appeared 55 times and was the most common answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer\n",
      "Henry VIII    44\n",
      "Solomon       27\n",
      "Louis XIV     25\n",
      "Sweden        24\n",
      "David         24\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def count_unique_answers(df):\n",
    "    \"\"\"\n",
    "    Counts the occurrences of unique answers in the dataset.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The filtered DataFrame containing a column named 'Answer'.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: A series with unique answers as the index and their counts as values.\n",
    "    \"\"\"\n",
    "    if 'Answer' not in df.columns:\n",
    "        raise KeyError(\"The dataset must contain an 'Answer' column.\")\n",
    "\n",
    "    # Count occurrences of each unique answer\n",
    "    return df['Answer'].value_counts()\n",
    "\n",
    "# Filter the dataset for questions containing the word \"King\"\n",
    "words_to_be_filtered = filter_questions_by_words(questions, [\"King\"])\n",
    "\n",
    "# Get the count of unique answers\n",
    "unique_answer_counts = count_unique_answers(words_to_be_filtered)\n",
    "\n",
    "# Display the most common answers\n",
    "print(unique_answer_counts.head(5))  # Show the top 10 most common answers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Explore from here! This is an incredibly rich dataset, and there are so many interesting things to discover. There are a few columns that we haven't even started looking at yet. Here are some ideas on ways to continue working with this data:\n",
    "\n",
    " * Investigate the ways in which questions change over time by filtering by the date. How many questions from the 90s use the word `\"Computer\"` compared to questions from the 2000s?\n",
    " * Is there a connection between the round and the category? Are you more likely to find certain categories, like `\"Literature\"` in Single Jeopardy or Double Jeopardy?\n",
    " * Build a system to quiz yourself. Grab random questions, and use the <a href=\"https://docs.python.org/3/library/functions.html#input\">input</a> function to get a response from the user. Check to see if that response was right or wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions in the 1990s with 'Computer': 98\n",
      "Questions in the 2000s with 'Computer': 268\n"
     ]
    }
   ],
   "source": [
    "def filter_questions_by_date_and_word(df, start_year, end_year, word):\n",
    "    \"\"\"\n",
    "    Filters questions in a given date range that contain a specific word.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The dataset.\n",
    "        start_year (int): Start year of the date range.\n",
    "        end_year (int): End year of the date range.\n",
    "        word (str): Word to filter the questions by.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A filtered DataFrame containing questions that match the criteria.\n",
    "    \"\"\"\n",
    "    # Convert 'Air Date' to datetime format if not already\n",
    "    df['Air Date'] = pd.to_datetime(df['Air Date'])\n",
    "\n",
    "    # Filter by date range and word\n",
    "    filtered_df = df[\n",
    "        (df['Air Date'].dt.year >= start_year) &\n",
    "        (df['Air Date'].dt.year <= end_year) &\n",
    "        (df['Question'].str.contains(word, case=False, na=False))\n",
    "    ]\n",
    "    return filtered_df\n",
    "\n",
    "# Questions containing \"Computer\" in the 1990s\n",
    "computer_90s = filter_questions_by_date_and_word(questions, 1990, 1999, \"Computer\")\n",
    "\n",
    "# Questions containing \"Computer\" in the 2000s\n",
    "computer_2000s = filter_questions_by_date_and_word(questions, 2000, 2009, \"Computer\")\n",
    "\n",
    "# Print the counts\n",
    "print(f\"Questions in the 1990s with 'Computer': {len(computer_90s)}\")\n",
    "print(f\"Questions in the 2000s with 'Computer': {len(computer_2000s)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round\n",
      "Double Jeopardy!    381\n",
      "Final Jeopardy!      10\n",
      "Jeopardy!           105\n",
      "Tiebreaker            0\n",
      "Name: LITERATURE, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def category_by_round_analysis(df):\n",
    "    \"\"\"\n",
    "    Analyzes the connection between the round and the category.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The dataset.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A table showing the frequency of categories per round.\n",
    "    \"\"\"\n",
    "    # Create a pivot table of rounds vs categories\n",
    "    pivot_table = df.pivot_table(\n",
    "        index='Category', \n",
    "        columns='Round', \n",
    "        aggfunc='size', \n",
    "        fill_value=0\n",
    "    )\n",
    "    return pivot_table\n",
    "\n",
    "# Analyze the connection\n",
    "category_round_table = category_by_round_analysis(questions)\n",
    "\n",
    "# Inspect specific categories\n",
    "print(category_round_table.loc['LITERATURE'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
